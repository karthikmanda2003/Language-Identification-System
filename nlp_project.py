# -*- coding: utf-8 -*-
"""NLP PROJECT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Rvb-zokOj_uIZJmdLfE2f8H2WeCCqMHd
"""

! pip install librosa

import os
import re
import shutil
import librosa
import numpy as np
import pandas as pd
import random

source_dir = 'C:\Users\Karthik\Downloads\archive.zip\train\train'

destination_dir = 'C:\Users\Karthik\Desktop\nlp project\output_train'

language_patterns = {
     'en': re.compile('^en', re.IGNORECASE),  # English
     'es': re.compile('^es', re.IGNORECASE),  # spanish
     'de': re.compile('^de', re.IGNORECASE),  # German

}

# split and save
def classify_and_store_audio_by_language(filename, destination_dir):
     for lang_code, pattern in language_patterns.items():
         if re.match(pattern, os.path.basename(filename)):

             lang_dir = os.path.join(destination_dir, lang_code)
             os.makedirs(lang_dir, exist_ok=True)
             shutil.copy(filename, lang_dir)
             return lang_code
     return 'unknown'

for filename in os.listdir(source_dir):
   if filename.endswith('.flac'):
        source_file_path = os.path.join(source_dir, filename)
        lang_code = classify_and_store_audio_by_language(source_file_path, destination_dir)

def feature_extraction(file_path):
    x,sample_rate=librosa.load(file_path)
    mfcc=np.mean(librosa.feature.mfcc(y=x,sr=sample_rate,n_mfcc=128*2).T,axis=0)
    return mfcc

mfcc_English={}
i=0

directory ="output_train/en/"
for audio in os.listdir(directory):
    if i<3000:
        audio_path=directory+audio
        mfcc_English[audio_path]=feature_extraction(audio_path)
        i=i+1
mfcc_Spanish={}
i=0

directory = "output_train/es/"
for audio in os.listdir(directory):
    if i<3000:
        audio_path=directory+audio
        mfcc_Spanish[audio_path]=feature_extraction(audio_path)
        i=i+1
mfcc_German={}
i=0


directory = "output_train/de/"
for audio in os.listdir(directory):
    if i<3000:
        audio_path=directory+audio
        mfcc_German[audio_path]=feature_extraction(audio_path)
        i=i+1

combined_features = {}

for lang, features in [("English", mfcc_English), ("German", mfcc_German), ("Spanish", mfcc_Spanish)]:
    for audio_path, feature in features.items():
        combined_features[audio_path] = {"MFCC": feature, "Lang_code": lang}

# Convert to DataFrame
df = pd.DataFrame.from_dict(combined_features, orient='index')

# Shuffle the dataset
df = df.sample(frac=1).reset_index(drop=True)

df

from sklearn.model_selection import train_test_split

X = np.array(df['MFCC'].tolist())

Y = np.array(df['Lang_code'].tolist())

X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.2)

from sklearn.neural_network import MLPClassifier

clf = MLPClassifier(solver='adam', alpha=0.00001, random_state=1)# multi-layerd perceptron

clf.fit(X_train,Y_train)

clf.score(X_test,Y_test)

clf.predict(X_test)

mfcc_English={}
# dataset test data

directory ="output_test/en/"
for audio in os.listdir(directory):

        audio_path=directory+audio
        mfcc_English[audio_path]=feature_extraction(audio_path)

mfcc_Spanish={}


directory = "output_test/es/"
for audio in os.listdir(directory):

        audio_path=directory+audio
        mfcc_Spanish[audio_path]=feature_extraction(audio_path)

mfcc_German={}


directory = "output_test/de/"
for audio in os.listdir(directory):

        audio_path=directory+audio
        mfcc_German[audio_path]=feature_extraction(audio_path)

combined_features = {}

for lang, features in [("English", mfcc_English), ("German", mfcc_German), ("Spanish", mfcc_Spanish)]:
    for audio_path, feature in features.items():
        combined_features[audio_path] = {"MFCC": feature, "Lang_code": lang}

test_df = pd.DataFrame.from_dict(combined_features, orient='index')

test_df= df.sample(frac=1).reset_index(drop=True)

test_df

testing = np.array(test_df['MFCC'].tolist())

clf.predict(testing)

